{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467d4192-4e39-4a5d-8bd3-732e302723c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import preprocessing\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297bf123-e1ce-4509-b047-009bc414bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('News_Dataset.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a4a864-348d-4acb-b387-8909b2e58b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092a3465-b834-4c0b-8af2-075444b1b0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/rim-ceo-t...</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>TECH</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "      <td>Reuters, Reuters</td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/maria-sha...</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "      <td></td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/super-bow...</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "      <td></td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/aldon-smi...</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "      <td></td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/dwight-ho...</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "      <td></td>\n",
       "      <td>2012-01-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     link  \\\n",
       "209522  https://www.huffingtonpost.com/entry/rim-ceo-t...   \n",
       "209523  https://www.huffingtonpost.com/entry/maria-sha...   \n",
       "209524  https://www.huffingtonpost.com/entry/super-bow...   \n",
       "209525  https://www.huffingtonpost.com/entry/aldon-smi...   \n",
       "209526  https://www.huffingtonpost.com/entry/dwight-ho...   \n",
       "\n",
       "                                                 headline category  \\\n",
       "209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...     TECH   \n",
       "209523  Maria Sharapova Stunned By Victoria Azarenka I...   SPORTS   \n",
       "209524  Giants Over Patriots, Jets Over Colts Among  M...   SPORTS   \n",
       "209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   SPORTS   \n",
       "209526  Dwight Howard Rips Teammates After Magic Loss ...   SPORTS   \n",
       "\n",
       "                                        short_description           authors  \\\n",
       "209522  Verizon Wireless and AT&T are already promotin...  Reuters, Reuters   \n",
       "209523  Afterward, Azarenka, more effusive with the pr...                     \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...                     \n",
       "209525  CORRECTION: An earlier version of this story i...                     \n",
       "209526  The five-time all-star center tore into his te...                     \n",
       "\n",
       "             date  \n",
       "209522 2012-01-28  \n",
       "209523 2012-01-28  \n",
       "209524 2012-01-28  \n",
       "209525 2012-01-28  \n",
       "209526 2012-01-28  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6048e1-674f-4594-9200-724f9bfaceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d21261cb-48ff-436a-914e-f99009e95957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d81470f-963c-48e6-9495-b2ab608e0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03340759-82a6-4576-b679-65813f380128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c766977e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Over 4 Million Americans Roll Up Sleeves For O...\n",
       "1    American Airlines Flyer Charged, Banned For Li...\n",
       "Name: combined, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['headline', 'short_description']\n",
    "df['combined'] = df[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "df.combined[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123c28ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deadly coral disease linked to ship wastewater_the in coral in the are linked by to the stony coral tissue loss disease which may be triggered by ship traffic'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "def preprocess_text(text):\n",
    "    \"\"\" Apply any preprocessing methods\"\"\"\n",
    "    str1 = \" \"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     word_tokens = word_tokenize(text)\n",
    "#     filtered = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    \n",
    "#     com = str1.join(filtered)\n",
    "    return text\n",
    "\n",
    "df[\"combined\"] = df.combined.apply(preprocess_text)\n",
    "df.combined[2284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3df7a74-95b6-4b59-8f72-f9d411e4d41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', ..., 'čechomor_čechomor', 'κάιρο_',\n",
       "       'ᵒᴥᵒᶅ_the'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "documents_vectorized = vectorizer.fit_transform(df['combined'])\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fcc59ab-0605-4a6a-ad36-d96db1267ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a 209514 document corpus with a 172143 term vocabulary\n"
     ]
    }
   ],
   "source": [
    "print ('We have a {} document corpus with a {} term vocabulary'.format(*documents_vectorized.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eee167ef-5773-42c5-9a34-a147f48c0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(documents_vectorized.toarray(), columns=vocabulary)\n",
    "doc_ids = dataframe.index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b38dad-49ef-4b4a-ad00-8f777f0ba199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000064</th>\n",
       "      <th>0000_remember</th>\n",
       "      <th>0001_were</th>\n",
       "      <th>0002</th>\n",
       "      <th>000foot</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzs_and</th>\n",
       "      <th>zzzs_rather</th>\n",
       "      <th>zzzs_snooze</th>\n",
       "      <th>½year</th>\n",
       "      <th>émigrés_the</th>\n",
       "      <th>étienne_william</th>\n",
       "      <th>ñ_director</th>\n",
       "      <th>čechomor_čechomor</th>\n",
       "      <th>κάιρο_</th>\n",
       "      <th>ᵒᴥᵒᶅ_the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  000064  0000_remember  0001_were  0002  000foot  001  0010  \\\n",
       "0   0    0     0       0              0          0     0        0    0     0   \n",
       "1   0    0     0       0              0          0     0        0    0     0   \n",
       "2   0    0     0       0              0          0     0        0    0     0   \n",
       "3   0    0     0       0              0          0     0        0    0     0   \n",
       "4   0    0     0       0              0          0     0        0    0     0   \n",
       "\n",
       "   ...  zzzs_and  zzzs_rather  zzzs_snooze  ½year  émigrés_the  \\\n",
       "0  ...         0            0            0      0            0   \n",
       "1  ...         0            0            0      0            0   \n",
       "2  ...         0            0            0      0            0   \n",
       "3  ...         0            0            0      0            0   \n",
       "4  ...         0            0            0      0            0   \n",
       "\n",
       "   étienne_william  ñ_director  čechomor_čechomor  κάιρο_  ᵒᴥᵒᶅ_the  \n",
       "0                0           0                  0       0         0  \n",
       "1                0           0                  0       0         0  \n",
       "2                0           0                  0       0         0  \n",
       "3                0           0                  0       0         0  \n",
       "4                0           0                  0       0         0  \n",
       "\n",
       "[5 rows x 172143 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6245f219-b910-4fdf-b5e7-5d4f4bb7ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25_IDF_df(df):\n",
    "  \"\"\"\n",
    "  This definition calculates BM25-IDF weights before hand as done last week\n",
    "  \"\"\"\n",
    "\n",
    "  dfs = (df > 0).sum(axis=0)\n",
    "  N = df.shape[0]\n",
    "  idfs = -np.log(dfs / N)\n",
    "  \n",
    "  k_1 = 1.2\n",
    "  b = 0.8\n",
    "  dls = df.sum(axis=1) \n",
    "  avgdl = np.mean(dls)\n",
    "\n",
    "  numerator = np.array((k_1 + 1) * df)\n",
    "  denominator = np.array(k_1 *((1 - b) + b * (dls / avgdl))).reshape(N,1) \\\n",
    "                         + np.array(df)\n",
    "\n",
    "  BM25_tf = numerator / denominator\n",
    "\n",
    "  idfs = np.array(idfs)\n",
    "\n",
    "  BM25_score = BM25_tf * idfs\n",
    "  return pd.DataFrame(BM25_score, columns=vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce88c13-8185-43e3-871e-415de8996ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/usamaal-attia/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/gf/9676_22j2d94hj9mxjytm1qw0000gn/T/ipykernel_6508/309118988.py:23: RuntimeWarning: invalid value encountered in multiply\n",
      "  BM25_score = BM25_tf * idfs\n",
      "/Users/usamaal-attia/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/gf/9676_22j2d94hj9mxjytm1qw0000gn/T/ipykernel_6508/309118988.py:23: RuntimeWarning: invalid value encountered in multiply\n",
      "  BM25_score = BM25_tf * idfs\n",
      "/var/folders/gf/9676_22j2d94hj9mxjytm1qw0000gn/T/ipykernel_6508/1891289038.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bm25_df.append(bm25_df1, ignore_index = True)\n",
      "/Users/usamaal-attia/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/gf/9676_22j2d94hj9mxjytm1qw0000gn/T/ipykernel_6508/309118988.py:23: RuntimeWarning: invalid value encountered in multiply\n",
      "  BM25_score = BM25_tf * idfs\n",
      "/var/folders/gf/9676_22j2d94hj9mxjytm1qw0000gn/T/ipykernel_6508/1891289038.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bm25_df.append(bm25_df1, ignore_index = True)\n",
      "/Users/usamaal-attia/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/gf/9676_22j2d94hj9mxjytm1qw0000gn/T/ipykernel_6508/309118988.py:23: RuntimeWarning: invalid value encountered in multiply\n",
      "  BM25_score = BM25_tf * idfs\n",
      "/var/folders/gf/9676_22j2d94hj9mxjytm1qw0000gn/T/ipykernel_6508/1891289038.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  bm25_df.append(bm25_df1, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000064</th>\n",
       "      <th>0000_remember</th>\n",
       "      <th>0001_were</th>\n",
       "      <th>0002</th>\n",
       "      <th>000foot</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzs_and</th>\n",
       "      <th>zzzs_rather</th>\n",
       "      <th>zzzs_snooze</th>\n",
       "      <th>½year</th>\n",
       "      <th>émigrés_the</th>\n",
       "      <th>étienne_william</th>\n",
       "      <th>ñ_director</th>\n",
       "      <th>čechomor_čechomor</th>\n",
       "      <th>κάιρο_</th>\n",
       "      <th>ᵒᴥᵒᶅ_the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  000064  0000_remember  0001_were  0002  000foot  001  0010  \\\n",
       "0 NaN  NaN   NaN     NaN            NaN        NaN   NaN      NaN  NaN   NaN   \n",
       "1 NaN  NaN   NaN     NaN            NaN        NaN   NaN      NaN  NaN   NaN   \n",
       "2 NaN  NaN   NaN     NaN            NaN        NaN   NaN      NaN  NaN   NaN   \n",
       "3 NaN  NaN   NaN     NaN            NaN        NaN   NaN      NaN  NaN   NaN   \n",
       "4 NaN  NaN   NaN     NaN            NaN        NaN   NaN      NaN  NaN   NaN   \n",
       "\n",
       "   ...  zzzs_and  zzzs_rather  zzzs_snooze  ½year  émigrés_the  \\\n",
       "0  ...       NaN          NaN          NaN    NaN          NaN   \n",
       "1  ...       NaN          NaN          NaN    NaN          NaN   \n",
       "2  ...       NaN          NaN          NaN    NaN          NaN   \n",
       "3  ...       NaN          NaN          NaN    NaN          NaN   \n",
       "4  ...       NaN          NaN          NaN    NaN          NaN   \n",
       "\n",
       "   étienne_william  ñ_director  čechomor_čechomor  κάιρο_  ᵒᴥᵒᶅ_the  \n",
       "0              NaN         NaN                NaN     NaN       NaN  \n",
       "1              NaN         NaN                NaN     NaN       NaN  \n",
       "2              NaN         NaN                NaN     NaN       NaN  \n",
       "3              NaN         NaN                NaN     NaN       NaN  \n",
       "4              NaN         NaN                NaN     NaN       NaN  \n",
       "\n",
       "[5 rows x 172143 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_df = BM25_IDF_df(dataframe[:1000])\n",
    "\n",
    "# for i in range(1000, 209514, 1000):\n",
    "#     bm25_df1 = BM25_IDF_df(dataframe[:i])  # a dataframe with BM25-idf weights\n",
    "#     bm25_df.append(bm25_df1, ignore_index = True)\n",
    "    \n",
    "for i in range(1000, 4000, 1000):\n",
    "    bm25_df1 = BM25_IDF_df(dataframe[:i])  # a dataframe with BM25-idf weights\n",
    "    bm25_df.append(bm25_df1, ignore_index = True)\n",
    "\n",
    "bm25_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b467111-3dbe-4d90-80ca-8c2a98091f63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0: ship wreck\n",
      "\n",
      "\n",
      "Query 1: little boat\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = dict(enumerate(['ship wreck',\n",
    "                          'little boat']))\n",
    "\n",
    "def retrieve_ranking(query, bm25_df):\n",
    "  q_terms = query.split(' ')\n",
    "  q_terms_only = bm25_df[q_terms]\n",
    "  score_q_d = q_terms_only.sum(axis=1)\n",
    "  return sorted(zip(bm25_df.index.values, score_q_d.values),\n",
    "                key = lambda tup:tup[1],\n",
    "                reverse=True)\n",
    "\n",
    "\n",
    "# Let's look at the first few scores for our query and document combinations:\n",
    "for count, query in enumerate(queries.values()):\n",
    "  print(f'Query {count}: {query}')\n",
    "  print('')\n",
    "  results = retrieve_ranking(query, bm25_df)\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86341192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[797, 237, 581, 832, 439, 766, 375, 671, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "for i in results[:10]:\n",
    "    final.append(i[0])\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5810cde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797    https://www.huffpost.com/entry/japan-shiretoko...\n",
       "237    https://www.huffpost.com/entry/inflation-reduc...\n",
       "581    https://www.huffpost.com/entry/kim-kardashian-...\n",
       "832    https://www.huffpost.com/entry/lizzo-youre-bea...\n",
       "439    https://www.huffpost.com/entry/funniest-tweets...\n",
       "766    https://www.huffpost.com/entry/samantha-bee-ma...\n",
       "375    https://www.huffpost.com/entry/dave-coulier-yo...\n",
       "671    https://www.huffpost.com/entry/health-insuranc...\n",
       "0      https://www.huffpost.com/entry/covid-boosters-...\n",
       "1      https://www.huffpost.com/entry/american-airlin...\n",
       "Name: link, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = df.loc[final, 'link']\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ca2123-80e6-4a50-8384-55e851902a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision_at_k(query_id, k=5):\n",
    "  \"\"\"This function considers the k top ranking documents.\"\"\"\n",
    "  doc_ranking = retrieve_ranking(queries[query_id], bm25_df)\n",
    "\n",
    "  # take only the document id, rather than score\n",
    "  retrieved = [doc[0] for doc in doc_ranking[:k]]\n",
    "\n",
    "  TP = ...  # number of true positives\n",
    "  FP = ...  # number of false positives \n",
    "\n",
    "  precision = ...\n",
    "\n",
    "  return TP, FP, precision\n",
    "\n",
    "\n",
    "# Let's see what we get when we consider the top 5 ranking documents:\n",
    "def print_precision_for_all_queries(k=5):\n",
    "  for query_id, query in queries.items():\n",
    "    TP, FP, precision = precision_at_k(query_id, k=k) \n",
    "    print(f'retrieved query \"{query}\" with precision @ {k}: {precision} (TP: {TP}, FP: {FP})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f752d1c-9bb2-4267-b156-24ce744522bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797    10 Found Dead After Japan Tour Boat Carrying 2...\n",
       "237    Democrats’ Inflation Reduction Act Expected To...\n",
       "581    Kim Kardashian Discusses Pete Davidson's 'BDE'...\n",
       "832    Determined Lizzo Tries To Break The 'Bitch' Re...\n",
       "439    The Funniest Tweets From Women This Week (June...\n",
       "766    Samantha Bee Stunned By 'Gossipy Little Bitch'...\n",
       "375    'Oh No': Dave Coulier Recalls Hearing Alanis M...\n",
       "671    Democrats Have Little Time To Avert An Electio...\n",
       "0      Over 4 Million Americans Roll Up Sleeves For O...\n",
       "1      American Airlines Flyer Charged, Banned For Li...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = df.loc[final, 'headline']\n",
    "headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdec0a8c-4267-4967-9df1-986474450dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797    The boat was sailing in an area known as a dif...\n",
       "237    The bill was also touted as lowering the defic...\n",
       "581    The reality star finally goes there on Hulu's ...\n",
       "832    She also addressed rumors that she's \"dating e...\n",
       "439    \"Sending friends tweets I think they might lik...\n",
       "766    \"Damn! Mark Meadows, you are messy,” she said....\n",
       "375    The \"Full House\" star revealed one big clue th...\n",
       "671    A subsidy boost for the Affordable Care Act th...\n",
       "0      Health experts said it is too early to predict...\n",
       "1      He was subdued by passengers and crew when he ...\n",
       "Name: short_description, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = df.loc[final, 'short_description']\n",
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756b793a-734f-4355-824f-7b4ccef3f9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
